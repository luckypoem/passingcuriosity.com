---
layout: post
title: FP-Syd October 2013
categories: [fpsyd, cellular automata, icfp, haskell, fusion]
tags: event, fp-syd, meetup, functional programming, icfp
contents: yes
location: Sydney, New South Wales
excerpt: 
  The October 2013 meeting of the FP-Syd functional programming group in Sydney
  heard talks about data flow fusion, a constrained domain specific language
  for building filesystems and a round-up of ICFP.
---

Little mention of [linux.conf.au 2014][lca2014] and how we should all take a
look at the available programme and see if we want to go.

[lca2014]: http://linux.conf.au/

# Erik's ICFP roundup

Erik was a long time LCA attendee but went to ICFP in Tokyo 3 years ago and
that is now his "must go" conference.

ICFP has a core three-day conference and a number of associated events.

## First day (Sunday)

*Haskell Implementers Workshop* covers the internals of Haskell implementations
which, these days, means GHC to a very large extent. Covers a lot of
interesting techniques, with a particular focus on compilers.

(In comparison, *Commercial Users* was, apparently, a little boring; a focus on
business cases?)

E.g. test case which makes generalised newtype deriving compile a segfaulting
program. Resolution is coming together in GHC-dev currently.

> Optimising your scrap your boilerplate with Hermit.
>
> Hermit is a framework/tool for doing dynamic and/or guided optimisation.

Habit - strict Haskell dialect for writing operating systems.

## Haskell Symposium

The Haskell Symposium was the main draw (for Erik).

Talk about Haskell at Galois; mostly of interested to those outside the Haskell
community.

Oleg asking difficult questions.

Quite a bit of effects

Small demoinstration of liquid types.

Hasacism - trying to emulate AGDA in Haskell.

Intel has a research compiler which uses the GHC front-end to Core and then
uses their own backend. Does loop vectorisation, currently only better
performance on a few benchmarks.

MIO - third iteration of the I/O manager for GHC. Multithreaded, influenced by
Yamamoto's work on Warp and mighttpd. Benchmarks against Nginx see very good;
Warp with multiple cores sees extremely good speedups (contra Nginx).

GHC - too big to fail?

Demonstration of the GHCJS Javascript backend for GHC.

Splittable pseudorandom number generator.

Interesting talk about optimising Haskell "What's burning all our cycles?"

## ICFP

There's a lot of stuff that goes straight over the top of a
practically-oriented working programmer.

Intel Haskell group did automated SIMD vectorisation.

Vectorised instructions with generalised stream fusion.

Optimising purely functional GPU programs.

A few on dependent types.

Typed tactic programming in Coq. (Tactics are untyped in Coq.)

Fun with semi-rings. People are encouraged to watch this video!

Efficient divide and conquer parsing of context free grammars. Partial and
parallel parsing.

Functional geometry and luthier - writing scheme programs to generate plans for
violins, etc.

Algebraic effects.

## ICFP - Thursday

SPJ on computer science as a school subject. New curriculum for secondary
computer science.

Correctness of STM.

Recursion and corecursion. Productive coprogramming. Patterns or something.

Functional reactive programming - Erik's takeaway was that FRP still has a long
way to go. They are starting to deal with a bunch of issues ("Higher-order
reactive programming without space-/time-leaks"). (May be being a bit harsh
though)

Lambda calculus.

System Fc with explicitly kind equality.

(See also System Fi - System F with type indices, you can have types in kinds
but they can't be inhabited. Everyone who can understand System F shouldn't
have a problem reading the System Fi paper.)

Constrained monad problem (which Oleg was crap). Paper on solving a problem
which occurred using Monads (for a DSL?), but should have used Applicative.
Mostly they wanted Monad sugar. See also Idiom brackets, and the attempt to
generalise monad sugar.

Querying ordered graphs.

Modular monadic metatheory.

Also: experience reports! Someone took a Scheme compiler from 4-5 to 25 passes
(nanoparsing?) and also added a good colouring register allocator.

Progamming logics, Hoare style, algebraic, etc.

## Friday

### Workshop on generic programming

Talking about a benchmark/framework to compare approaches to generic
programming.

### Functional Art Modelling and Design

Brent Yorgey - doing animations with `diagrams`. Apparently Nicholas? looked at
it and immediately reeled off what the types were actually from category theory.

Paul Hudak?

Chordify - chord transscript for the masses. Generate rough chord
transcriptions of sound recordings.

## Conclusion

ICFP is awesome and, if you get a chance, you should go.

# Ben talking about dataflow fusion

This is the paper Ben presented at ICFP.

Wants to process a list of points, adding 1 to each, filtering those about 0
and also finding the maximum.

Doing stream fusion

````{.haskell}
map f = unstream . mapsS f . stream
filter f = unstream . filterS f . stream

-- RULE to remove (stream . unstream)
````

Example computes `(vec3, n)` can't float `vec3` because it's being used in the
result *and* in the computation of `n`. So we get two loops.

    **1** -> 2 -> **3** -> 4
    	              |      |
                  (    ,    )

`zipWithX` tends to use X+1 loop counters for stream fusion. There're only 8
registeres to use on some platforms.

## Data Flow Fusion

### Slight manual refactor

Split `filter` into two combinators `flag` -- which contains `True` or `False`
for each member -- and `pack` -- which does the filtering.


### Extract the data flow graph

This code generates the data flow graph.

````
fun vec1 (\s1 -> 
  let s2    = map (+ 1) s1
      flags = map (> 0) s2
  in mkSel flags (\sel ->
  let s3   = pack sel s2
      vec3 = create s3
      n    = fold max 0 s3
  in (vec3, n)))

vec1 :: Vector Int
s1 :: Series k1 Int
s2 :: Series k1 Int
flags :: Sel k1 k2
s3 :: Series k2 Int
````

Series has a phantom type variable which helps keep track of the code which can
be fused into a single loop.

We learn that `k1 >= k2`

With the flow graph (annotated with operations, etc.), throw away the source.

### Schedule the grapch into an abstract loop nest

Abstract loop nest:

````
loop k1 {

  start: ....
  
  body: ....
  
  inner: ...
  
  end: ...

} yields ...
````

Start at the front of the data flow graph and add elements of the graph to the
nested abstract loop.

Operations go into different places in the nested abstract loop. A `fold`, for
example, allocates and accumulator in `start`, increments somewhere within
`body` and reads it in `end`.

### Extract implementsation from abstract loop nest.

Translate bits and pieces of the abstract loop nest into different Haskell
combinators.

## Implementation

GHC plugin which grabs Core, does data flow compilation and generates Core to
give back to GHC.

Some issues in current implementation where LLVM doesn't realise that writing
to the output doesn't *need* to reload the start and length numbers.

> **If** your program isa first order (argument functions take scalars,
> not series), non-recursive, synchronous, finite data flow program
> using out combinators.
>
> **Then** by construction your program will be compiled correctly by
> this system.


# Liam on CDSL

Liam O'Connor works for NICTA. Instead of talking about something he recently
learned, he's talking about work: CDSL - a restricted functional language for
file system verification.

Trying to establish a formal proof of the correctness of a file system driver
in an operating system.

Already have an architecture for this sort of problem (from seL4):

1. Abstract spec - highlevel, nondeterministic (followed by an "interesting"
proof of relation to ~ 15%)

2. Low level spec - purely functional (followed by a "largely boring" proof of
relation to ~ 30%)

3. C implementation - efficient.

~ 55% is showing that the other proofs don't do something stupid; proving
invariants all hold.

Ignoring the kernel proper, architecture support and drivers (another NICTA
project), the largest part of the Linux kernel is the `fs/` directory. 31
supported in the kernel running on some random NICTA server.

Lots of file systems with, one assumes, quite a lot of common functionality and
infrastructure. Goal here is not to make a cathedral of a single verified file
system, more a factory for churning out numerous file systems.

Approach here is to use a DSL to generate the low-level spec, proof and
implementation. High-level spec and proof are done by hand, so generated
outputs should be readable.

Should

- establish key verification properties

- compete to efficient C code (imperative, destructive updates, etc.)

- expressive enough to write a file system

But:

- Don't need to express *everything* in a file system. Hand-written components
  could be plugged in to the DSL (and, hopefully, re-used).

## Simply-typed lambda calculus

Simple-typed lamba calculus is stronyl normalising (you can't write general
recursion, e.g. the Y combinator).

First-order language: lambdas go away, use `let` binding and restrict to
defining top-level functions. Added structural rules for mixing, weakening, ?

Need to do memory management which is safe, expressive (no pass by value, we
need the heap), no GC (you'd have to verify it, introduce latency, etc.)

Automatic member management (GC) is too big a burden. Many static automatic
memory management is inefficient or unsafe.

What about manual memory management?

````{.haskell}
let x = allocateData ()
    x' = updateData x
    _ = free x
in x'
````

But this is terrible! Unsafe, inefficient, etc.

So have a linear type system, throwing away weakening, etc. Forces use of
things exactly matching (can't alloc and not use, doesn't discharge the new
fact). The typing rules require that introduction and elemination be paired.

Linear types means that the elimination operations (e.g. `updateDate`) are the
*last* to access terms, so they can do destructive updates.

Two interpresations of these semantics:

- value semantics: pass by value, no heap, immutability, reasoning.

- update semantics: heap, updates, deallocates, implementation.

Linear types allow for both.

But sometimes you want non-linear, pass-by-value (arithmetic operations, etc.):

- Unboxed types, ints, small structs
- Functions themselves

Allow structural rules (dereliction and contraction) for certain types only. So
now we have `T_{.}` and `T_{#}` (unboxed and value types).


## Buffer interface

````
make : () -> .Buf
free : .Buf -> ()
length : .Buf -> (#U32, .Buf)

serialise : (.Obj, .Buf) -> (.Obj, .Buf)
deserialise : .Buf -> (.Obj, .Buf)
````

Non-linear "look but don't touch" references with `*`:

````
make : () -> .Buf
free : .Buf -> ()

length : *Buf -> #U32
serialise : (*Obj, .Buf) -> .Buf
deserialise : *Buf -> .Obj
````

Use `let!` construct which is like `let` but we mark specific variables as
read-only within the `let` clauses and back to linear in the `in`.

But this is unsafe (read-only can escape the let). Could use regions, but
choose not to unless it's required.

Linear typing breaks some control flow:

````{.haskell}
let x = alloc ()
in if cond
   then update(x)
   else x
````

## Loops

Hardest, most annoying part of the formalisation of the language.

Built-in loop combinators, map, fold, with, for.

````
let sum = for (x,y) in fold(arr) with 0
              do (x + y)

let arr', sum = for (x,y) in map(arr) with 0
                    do (x * 2, x + y)
````

Alas, this is unsafe. Double free, etc. But you can restrict linear types in
the loop expression. Then have to make any required linear types into
accumulator parms.

## Error handling

The return-code convention using in languages like C is pretty bad. Instead,
separate statements and expressions.

Statements have three types:

- s : {\bar T_{s}}
- s : fails {\bar T_{f}}
- s : {\bar T_{?}} fails {\bar T_{?}}

Type of `if then else` is `T_{t} \leastupperbound T_{e}`. Lattice join,
subtype, etc.

Make `let` and `let!` only handle success cases. Force sub-expressions to
handle potential errors. Type system *forces* you to handle your errors and the
*linear* type system forces you to free your resources.

## Types

Product and sum types (implemented as structs and tagged unions).

Accessing members of linear records is problematic as you use the record
multiple times:

````
let sum = operation(x.field1, x.field2)
````

Instead use an open/close structure.

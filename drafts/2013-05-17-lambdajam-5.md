Datomic is a database with distributed reads, centralised writes, ACID. It isn't
relational and incorporates temporality. Has a declarative query language based
on Datalog (no MapRepduce).

Written in Clojure and Java. *Peer* library with APIs for Java and Clojure.
RESTful API for external clients.

Commerical product with free version (limited to 1 transactor, 2 peers). Pro
licensed based on number of peers, has support for more and more interesting
things.

# Data Model

Datomic is a database of *facts*. A fact is one piece of information, about
one thing, at a specific point in time. Facts are immutable. Thus the "value"
of a database is persistent.

An entity is a collection of facts about "one thing". An entity can be viewed
as a map. Can be treated as a graph, traversing the relationships between
entities.

Facts are stored as 4-tuples called a *datom*. This is very similar to RDF with
an additional time value.

Facts:

1. Entity ID (integer)
2. Attribute (clojure keyword)
3. Value
4. Time (number of transactions since the beginnning of time).

Retaction of facts.

Excision - deleting all knowledge of a fact - is a new feature (<= 2 weeks).
This leaves gaps in the transaction log, so there's no chance of plausible
deniability.

# Transactions

Each txn is a sequence of vectors which describe the operations performed.

	;; transaction input is data
	(def tx
		[[:db/add
		  (d/tempid :db.part/user)  ; entity
		  :db/doc                   ; attribute
	      "Hello world"]])          ; value

Pass this to `datomic.api/transact` to perform the transaction.

# Database values

`datomic.api/db` returns a database "value". These are persistent. These values
are passed into a query, making query a pure operation.

# Architecture

## Peer library

The peer library is embedded within the application and executes queries
locally. To do this, it fetches and caches data (compressed index segments)
from the storage service.

This gives us data locality for queries if the working set fits into the local
cache. So we scale horizontally by partitioning the workload rather than the
data, as in other databases.

## Transactor

Handles writing for the whole database. This imposes a serialisation on
transactions and makes ACID guarantees.

Prepares transaction logs and generates indexes and sends them to the storage
services. Committed transactions are broadcast to all peers so that they can
update their caches and, potentially, respond to changes in the database.

Hot standby for failover. Supports 2 nodes.

## Storage Service

Storage is a service and there are several different backend implementations.
Memory and filesystem storage can be used (on the transactor node).

The Pro version can use an SQL database as storage. Also has support for a
number of distributed storage services: AWS DynamoDB, Infinispan, Riak,
Couchbase. DynamoDB is probably the most frequently and well-tested storage
backend.

There is no public API for writing storage backends.

# Query

	(d/q '[:find ?e
	       :in $ ?email
           :where [?e :user/email ?email]]
         db
         "editor@example.com")

The `:in` clause matches the subsequent arguments to the `q` function, `$` is
a placeholder for the single DB.

# Attributes

`_` at the start of an attribute name indicates that it's reversed?

Can be unique in two ways:

1. Uniqueness of value at a point in time.

2. Uniqueness of identity, which identifies an entity.

# Transactions

Multiple ways to handle consistency:

1. Just send changes.

2. Send function to do query in the transactor. It can check conditions, etc.
   during application.

3. Send data and assumptions. Doesn't apply data unless assumptions still true.

Upsert by using identity attributes. 
